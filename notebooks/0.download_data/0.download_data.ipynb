{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Downloadling MitoCheck data\n",
                "\n",
                "In this notebook, we're fetching MitoCheck image-based profiles from this [repository](https://zenodo.org/records/7967386). Since the data is quite large, the download process may take slightly over an hour. Once downloaded, you'll receive a compressed zip file, which needs to be uncompressed. Then, we extract the image-based profiles (in CSV format) and convert them to Parquet for quicker loading times."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pathlib\n",
                "import zipfile\n",
                "\n",
                "import pandas as pd\n",
                "import requests"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Parameters and File Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "url = \"https://zenodo.org/records/7967386/files/3.normalize_data__normalized_data.zip?download=1\"\n",
                "chunk_size = 8192\n",
                "\n",
                "# setting data directory path\n",
                "data_dir = pathlib.Path(\"../../data\").resolve(strict=True)\n",
                "\n",
                "# create raw sub directory\n",
                "raw_data_dir = (data_dir / \"raw\").resolve()\n",
                "raw_data_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# output file name\n",
                "data_out_path = (raw_data_dir / \"3.normalize_data__normalized_data.zip\").resolve()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Downloading the dataset from he Zenodoo repository."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# downloading training data using requests\n",
                "with requests.get(url, stream=True) as r:\n",
                "    # raise error if the there's an error\n",
                "    r.raise_for_status()\n",
                "\n",
                "    # creating a file to write the downloaded contents in chunks\n",
                "    with open(data_out_path, mode=\"wb\") as out_file:\n",
                "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
                "            out_file.write(chunk)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# then lets unzip the file\n",
                "with zipfile.ZipFile(data_out_path, mode=\"r\") as zip_file_contents:\n",
                "    zip_file_contents.extractall(raw_data_dir / \"mitocheck_data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Converting to parquet files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "mitocheck_data_paths = list(\n",
                "    pathlib.Path(\"../../data/raw/mitocheck_data/normalized_data\").glob(\"*.csv.gz\")\n",
                ")\n",
                "for path in mitocheck_data_paths:\n",
                "    name = path.name.split(\".\")[0]\n",
                "    parquet_path = path.parent.resolve() / f\"{name}.parquet\"\n",
                "\n",
                "    # load in csv file\n",
                "    df = pd.read_csv(path)\n",
                "    # converting into parquet file\n",
                "    df.to_parquet(parquet_path, index=False)\n",
                "\n",
                "    # remove csv file\n",
                "    os.remove(path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "final",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
